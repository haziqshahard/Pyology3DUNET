{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "device name Quadro RTX 6000\n"
     ]
    }
   ],
   "source": [
    "import torch, torchinfo\n",
    "import torch.nn as nn\n",
    "#from torchsummary import summary\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn.functional as F\n",
    "#import torchvision.transforms.functional as TF\n",
    "\n",
    "#checking for device\n",
    "device=torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "\n",
    "if not torch.cuda.is_available():\n",
    "  raise Exception(\"GPU not available. CPU training will be too slow.\")\n",
    "\n",
    "print(\"device name\", torch.cuda.get_device_name(0))\n",
    "\n",
    "class DoubleConv(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(DoubleConv, self).__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv3d(in_channels, out_channels, (3,3,3), 1, 1, bias = False),\n",
    "            #Need to be careful about the kernel size, might need to change to 3,3,3\n",
    "            nn.BatchNorm3d(out_channels), #BatchNorm \n",
    "            #These parameters set it to a same convolution\n",
    "            #False bias used because batchnorm\n",
    "            nn.ReLU(inplace = True),\n",
    "            nn.Conv3d(out_channels, out_channels, (3,3,3), 1, 1, bias = False),\n",
    "            nn.BatchNorm3d(out_channels), #BatchNorm \n",
    "            #These parameters set it to a same convolution\n",
    "            #False bias used because batchnorm\n",
    "            nn.ReLU(inplace = True)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.conv(x)\n",
    "    \n",
    "\n",
    "class UNET(nn.Module):\n",
    "    def __init__(\n",
    "            #set to 16, 32, 64 just to test for now\n",
    "        self, in_channels=1, out_channels = 3, features =[16,32,64], \n",
    "        #Output channels set to 2 such that we get 3 different classes for:\n",
    "            #0 - Background\n",
    "            #1 - Myocardium\n",
    "            #2 - Cavity Volume\n",
    "    ):\n",
    "        super(UNET, self).__init__()\n",
    "        self.ups = nn.ModuleList() #Storing Convolutional Layers for model.eval\n",
    "        self.downs = nn.ModuleList()\n",
    "        self.pool = nn.MaxPool3d(kernel_size=(2,2,2), stride=2)\n",
    "        #If image non-divisble by 2, can cause issues with concatenation\n",
    "        \n",
    "        #Down section of UNET\n",
    "        for feature in features:\n",
    "            self.downs.append(DoubleConv(in_channels, feature))\n",
    "            in_channels = feature\n",
    "            \n",
    "        #Up part of UNET\n",
    "        for feature in reversed(features):\n",
    "            self.ups.append(\n",
    "                nn.ConvTranspose3d(\n",
    "                    feature*2, feature, kernel_size = (2,2,2), stride = 2,  #Done because adding a skip connection\n",
    "                )\n",
    "            )\n",
    "            self.ups.append(DoubleConv(feature*2, feature))\n",
    "            \n",
    "        #Bottom layer of the UNET\n",
    "        self.bottom = DoubleConv(features[-1], features[-1]*2)\n",
    "        self.final_conv = nn.Conv3d(features[0], out_channels,kernel_size = (1,1,1))\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self,x):\n",
    "        skip_connections = []\n",
    "        for down in self.downs:\n",
    "            x = down(x)\n",
    "            skip_connections.append(x) #Add to skip connections\n",
    "            x = self.pool(x)\n",
    "            \n",
    "        x = self.bottom(x)\n",
    "        skip_connections = skip_connections[::-1]\n",
    "        \n",
    "        for idx in range(0, len(self.ups), 2):\n",
    "            #step size of 2 chosen as wanna do up, then doubleconv (counted as 2 steps)\n",
    "            x = self.ups[idx](x)\n",
    "            #print(x.shape)\n",
    "            skip_connection = skip_connections[idx//2]\n",
    "            \n",
    "            if x.shape != skip_connection.shape:\n",
    "               #print(skip_connection.shape[2:])\n",
    "                x = F.interpolate(x, size=skip_connection.shape[2:])\n",
    "                \n",
    "            concat_skip = torch.cat((skip_connection, x), dim=1)\n",
    "            x = self.ups[idx+1](concat_skip) #Running through double conv\n",
    "   \n",
    "        return self.sigmoid(self.final_conv(x))           \n",
    "        \n",
    "    \n",
    "def test():\n",
    "    imsize = 112\n",
    "    #x=torch.randn((2,1,96,96,96))\n",
    "    x=torch.randn((2,1,imsize, imsize, imsize))\n",
    "    model = UNET(in_channels=1, out_channels=1)\n",
    "    preds = model(x)\n",
    "    #print(preds.shape)\n",
    "    #print(x.shape)\n",
    "    assert preds.shape == x.shape\n",
    "    \n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    #test()\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:please]",
   "language": "python",
   "name": "conda-env-please-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
