{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"C:/Users/Haziq/OneDrive - Imperial College London/Third Year/Fetal VR Group Project/Files/Done files/SegmentationDev/4.notebook/notebookretry\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "%run dataset.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DiceLoss(nn.Module):\n",
    "    def __init__(self, weight=None, size_average=True):\n",
    "        super(DiceLoss, self).__init__()\n",
    "\n",
    "    def forward(self, inputs, targets, smooth=1):\n",
    "\n",
    "        #comment out if your model contains a sigmoid or equivalent activation layer\n",
    "        inputs = torch.sigmoid(inputs)\n",
    "\n",
    "        #flatten label and prediction tensors\n",
    "        inputs = torch.flatten(inputs)\n",
    "        targets = torch.flatten(targets)\n",
    "\n",
    "        intersection = (inputs * targets).sum()\n",
    "        dice = (2.*intersection + smooth)/(inputs.sum() + targets.sum() + smooth)\n",
    "\n",
    "        return 1-dice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dice(nn.Module):\n",
    "    def __init__(self, weight=None, size_average=True):\n",
    "        super(Dice, self).__init__()\n",
    "\n",
    "    def forward(self, inputs, targets, smooth=0):\n",
    "\n",
    "        #comment out if your model contains a sigmoid or equivalent activation layer\n",
    "        #inputs = torch.sigmoid(inputs)\n",
    "        \n",
    "        dinputs = torch.argmax(inputs, dim=1)\n",
    "\n",
    "        d1 = dice_coefficient(dinputs, targets, 1)\n",
    "        d2 = dice_coefficient(dinputs, targets, 2)\n",
    "        \n",
    "        dice = (d1+d2)/2\n",
    "\n",
    "        return dice       \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dicebleh(nn.Module):\n",
    "    def __init__(self, weight=None, size_average=True):\n",
    "        super(Dice, self).__init__()\n",
    "\n",
    "    def forward(self, inputs, targets, smooth=0):\n",
    "\n",
    "        #comment out if your model contains a sigmoid or equivalent activation layer\n",
    "        #inputs = torch.sigmoid(inputs)\n",
    "\n",
    "        \n",
    "        inputs = torch.argmax(inputs, dim=1)\n",
    "        # print(targets.size())\n",
    "\n",
    "        #flatten label and prediction tensors\n",
    "        inputs = torch.flatten(inputs)\n",
    "        targets = torch.flatten(targets)\n",
    "\n",
    "        intersection = (inputs * targets).sum()\n",
    "        dice = (2.*intersection + smooth)/(inputs.sum() + targets.sum() + smooth)\n",
    "\n",
    "        return dice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test the loss with 2 images to see if im getting the right values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dice_coefficient(y_true, y_pred, class_index):\n",
    "    # print(y_true == class_index)\n",
    "    intersection = torch.sum((y_true == class_index) & (y_pred == class_index))\n",
    "    union = torch.sum(y_true == class_index) + torch.sum(y_pred == class_index)\n",
    "    dice = (2. * intersection) / (union + 1e-9)  # Adding a small epsilon to avoid division by zero\n",
    "    return dice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DiceCELoss(nn.Module):\n",
    "    def __init__(self, weight=None, size_average=True):\n",
    "        super(DiceCELoss, self).__init__()\n",
    "\n",
    "    def forward(self, inputs, targets, smooth=1):\n",
    "\n",
    "        batchnum = targets.size(dim=0)\n",
    "        #print(targets.reshape(batchnum,112,112,112).size())\n",
    "\n",
    "        #flatten label and prediction tensors\n",
    "        #Doing it for just 1 and 2\n",
    "\n",
    "        dinputs = torch.argmax(inputs, dim=1)\n",
    "\n",
    "        d1 = dice_coefficient(dinputs, targets, 1)\n",
    "        # print(d1)\n",
    "        d2 = dice_coefficient(dinputs, targets, 2)\n",
    "        # print(d2)\n",
    "        \n",
    "        dice_loss = 1-((d1+d2)/2)\n",
    "        \n",
    "        \n",
    "        CE = F.cross_entropy(inputs, targets.reshape(batchnum,112,112,112).long(), reduction=\"mean\")\n",
    "        Dice_CE = CE + dice_loss\n",
    "\n",
    "        # print(\"CE:\", CE)\n",
    "        # print(\"DICE:\", dice_loss)\n",
    "        # print()\n",
    "\n",
    "        #Ignore the mask having 0 intensity\n",
    "        #Only consider level 1 and level 2\n",
    "        return Dice_CE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DiceCEMultiClassLoss(nn.Module):\n",
    "    def __init__(self, weight=None, size_average=True):\n",
    "        super(DiceCEMultiClassLoss, self).__init__()\n",
    "\n",
    "    def forward(self, inputs, targets, smooth=1):\n",
    "        \"\"\"The inputs are already being softmaxed\"\"\"\n",
    "        #comment out if your model contains a sigmoid or equivalent activation layer\n",
    "        #inputs = torch.sigmoid(inputs)\n",
    "        #flatten label and prediction tensors\n",
    "        #inputs = inputs.view(-1)\n",
    "        #targets = targets.view(-1)\n",
    "        # loss = F.cross_entropy()\n",
    "            \n",
    "        #Ignoring the background\n",
    "        numchan = inputs.size(dim=1)\n",
    "\n",
    "        # print(inputs.unique)\n",
    "        # print(targets.unique)\n",
    "\n",
    "        TotDice_CE = 0\n",
    "\n",
    "        for channel in range(numchan):\n",
    "            input_ = inputs[:,channel,:,:,:].resize(1,1,112,112,112)\n",
    "            target = targets[:,channel,:,:,:].resize(1,1,112,112,112)\n",
    "\n",
    "            intersection = (input_ * target).sum()\n",
    "            dice_loss = 1 - (2.*intersection + smooth)/(input_.sum() + target.sum() + smooth)\n",
    "            \n",
    "            CELOSS = F.binary_cross_entropy(input_, target, reduction=\"mean\").item()\n",
    "            Dice_CE = CELOSS + dice_loss\n",
    "\n",
    "            # print(input_.size())\n",
    "\n",
    "            # print(\"chan: \", channel)\n",
    "            # print(\"CE Loss:\", CELOSS)\n",
    "            # print(\"Dice Loss:\", dice_loss)\n",
    "            TotDice_CE += Dice_CE\n",
    "\n",
    "        TotDice_CE = TotDice_CE/numchan\n",
    "        # print(TotDice_CE)\n",
    "\n",
    "        return TotDice_CE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CELoss(nn.Module):\n",
    "    def __init__(self, weight=None, size_average=True):\n",
    "        super(CELoss, self).__init__()\n",
    "\n",
    "    def forward(self, inputs, targets, smooth=1):\n",
    "\n",
    "        #comment out if your model contains a sigmoid or equivalent activation layer\n",
    "        inputs = torch.sigmoid(inputs)\n",
    "\n",
    "        #flatten label and prediction tensors\n",
    "        inputs = inputs.view(-1)\n",
    "        targets = targets.view(-1)\n",
    "\n",
    "        loss = F.cross_entropy(inputs, targets)\n",
    "\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def dice_score_single_class(y_true, y_pred, class_index):\n",
    "    dice = dice_coefficient(y_true, y_pred, class_index)\n",
    "    return dice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dice tensor(1.6371)\n",
      "tensor([[[[False, False, False,  ..., False, False, False],\n",
      "          [False, False, False,  ..., False, False, False],\n",
      "          [False, False, False,  ..., False, False, False],\n",
      "          ...,\n",
      "          [False, False, False,  ..., False, False, False],\n",
      "          [False, False, False,  ..., False, False, False],\n",
      "          [False, False, False,  ..., False, False, False]],\n",
      "\n",
      "         [[False, False, False,  ..., False, False, False],\n",
      "          [False, False, False,  ..., False, False, False],\n",
      "          [False, False, False,  ..., False, False, False],\n",
      "          ...,\n",
      "          [False, False, False,  ..., False, False, False],\n",
      "          [False, False, False,  ..., False, False, False],\n",
      "          [False, False, False,  ..., False, False, False]],\n",
      "\n",
      "         [[False, False, False,  ..., False, False, False],\n",
      "          [False, False, False,  ..., False, False, False],\n",
      "          [False, False, False,  ..., False, False, False],\n",
      "          ...,\n",
      "          [False, False, False,  ..., False, False, False],\n",
      "          [False, False, False,  ..., False, False, False],\n",
      "          [False, False, False,  ..., False, False, False]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[False, False, False,  ..., False, False, False],\n",
      "          [False, False, False,  ..., False, False, False],\n",
      "          [False, False, False,  ..., False, False, False],\n",
      "          ...,\n",
      "          [False, False, False,  ..., False, False, False],\n",
      "          [False, False, False,  ..., False, False, False],\n",
      "          [False, False, False,  ..., False, False, False]],\n",
      "\n",
      "         [[False, False, False,  ..., False, False, False],\n",
      "          [False, False, False,  ..., False, False, False],\n",
      "          [False, False, False,  ..., False, False, False],\n",
      "          ...,\n",
      "          [False, False, False,  ..., False, False, False],\n",
      "          [False, False, False,  ..., False, False, False],\n",
      "          [False, False, False,  ..., False, False, False]],\n",
      "\n",
      "         [[False, False, False,  ..., False, False, False],\n",
      "          [False, False, False,  ..., False, False, False],\n",
      "          [False, False, False,  ..., False, False, False],\n",
      "          ...,\n",
      "          [False, False, False,  ..., False, False, False],\n",
      "          [False, False, False,  ..., False, False, False],\n",
      "          [False, False, False,  ..., False, False, False]]]])\n",
      "Dice multiclass score: tensor(1.)\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    import matplotlib.pyplot as plt\n",
    "    y = readNifti_mask(\"/home/yiho/Haziq/3D 112 Dataset/test/mask/Case_122_Pre/Case_122_Pre_mask_time002.nii\")\n",
    "    #Calculating Dice\n",
    "    \n",
    "    intersection = (y*y).sum()\n",
    "    dice = (2.*intersection)/(y.sum() + y.sum())\n",
    "    # print(\"Dice\", dice)\n",
    "\n",
    "    dice = dice_score_single_class(y, y, 2)\n",
    "    # print(\"Dice multiclass score:\", dice)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    pass\n",
    "    # main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "    y_softmax = F.softmax(y)\n",
    "\n",
    "    nnloss =  nn.CrossEntropyLoss()\n",
    "    loss = F.cross_entropy(y_softmax, y_softmax, reduction=\"mean\")\n",
    "    nnl = nnloss(y,y).item()\n",
    "    print(\"Cross Entropy Loss : \", loss)\n",
    "    print(\"nn loss: \", nnl)\n",
    "    \n",
    "    #Calculating Dice\n",
    "    intersection = (y*y).sum()\n",
    "    dice_loss = 1 - (2.*intersection + 1)/(y.sum() + y.sum() + 1)\n",
    "    print(\"Dice Loss :\", dice_loss)\n",
    "\n",
    "    # Generate identical matrices as input and target\n",
    "    input_matrix = torch.randn(10000, 5)  # Example input matrix\n",
    "    target_matrix = torch.randn(10000, 5)  # Example target matrix\n",
    "\n",
    "    # Compute softmax on the input matrix (assuming the raw output of your model)\n",
    "    input_softmax = F.softmax(input_matrix, dim=1)\n",
    "\n",
    "    # Compute cross-entropy loss\n",
    "    loss = F.cross_entropy(input_softmax, input_softmax)\n",
    "\n",
    "    print(loss.item())  # Print the loss value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pysegwst",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
